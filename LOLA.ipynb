{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "from keras.layers import *\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import keras, time\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoLa(Layer):\n",
    "    def __init__(self, nAdded, **kwargs):\n",
    "        # Set the number of added combinations\n",
    "        self.nAdded = nAdded\n",
    "        super(CoLa, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create trainable weight for the linear combination\n",
    "        self.combination = self.add_weight(name='combination',\n",
    "                    shape=(input_shape[2], self.nAdded),\n",
    "                    initializer='uniform',\n",
    "                    trainable=True)\n",
    "        super(CoLa, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Generate combinations and return input with appended with combinations\n",
    "        combined = K.dot(x, self.combination)\n",
    "        return K.concatenate([x, combined], axis=2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        self.out_shape = (input_shape[0], \n",
    "                    input_shape[1], \n",
    "                    input_shape[2] + self.nAdded)\n",
    "        return self.out_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        # Store nAdded value for loading saved models later\n",
    "        base_config = super(CoLa, self).get_config()\n",
    "        base_config['nAdded'] = self.nAdded\n",
    "        return base_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoLa(Layer):\n",
    "    \"\"\"Lorentz Layer adapted from arXiv:1707.08966\n",
    "    From an input of 4 vectors generate some physical quantities that serve as\n",
    "    input to a classifiction network\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LoLa, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = keras.initializers.TruncatedNormal(mean=0., stddev=0.1)\n",
    "        metric = keras.initializers.Constant(value=[[1., -1., -1., -1.]])\n",
    "        # Trainable metric for 4-vector multiplication\n",
    "        self.metric = self.add_weight(name='metric',\n",
    "                    shape=(1, 4),\n",
    "                    initializer=metric,\n",
    "                    trainable=True)\n",
    "\n",
    "        # Weights for the linear combination of energies\n",
    "        self.energyCombination = self.add_weight(name='energyCombination',\n",
    "                    shape=(input_shape[-1], input_shape[-1]),\n",
    "                    initializer=initializer,\n",
    "                    trainable=True)\n",
    "        \n",
    "        # Weights for the linear combinations of distances\n",
    "        self.distanceCombination = self.add_weight(name='distanceCombination',\n",
    "                    shape=(input_shape[2], 4),\n",
    "                    initializer=initializer,\n",
    "                    trainable=True)\n",
    "        super(LoLa, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        def getDistanceMatrix(x):\n",
    "            \"\"\"Input:\n",
    "            x, (batchsize, features, nConst) - array of vectors\n",
    "            Returns:\n",
    "            dists, (batchsize, nConst, nConst) - distance array for every jet\n",
    "            \"\"\"\n",
    "            part1 = -2 * K.batch_dot(x, K.permute_dimensions(x, (0, 2, 1)))\n",
    "            part2 = K.permute_dimensions(K.expand_dims(K.sum(x**2, axis=2)), (0, 2, 1))\n",
    "            part3 = K.expand_dims(K.sum(x**2, axis=2))\n",
    "            dists = part1 + part2 + part3\n",
    "            return dists\n",
    "\n",
    "        # Get mass of each 4-momentum\n",
    "        mass = K.dot(self.metric, K.square(x))\n",
    "        mass = K.permute_dimensions(mass, (1, 0, 2))\n",
    "\n",
    "        # Get pT of each 4-momentum\n",
    "        pT = x[:, 1, :] ** 2 + x[:, 2, :] ** 2\n",
    "        pT = K.sqrt(K.reshape(pT, (K.shape(pT)[0], 1, K.shape(pT)[1])))\n",
    "        \n",
    "        # Get a learnable linear combination of the energies of all constituents\n",
    "        energies = K.dot(x[:, 0, :], self.energyCombination)\n",
    "        energies = K.reshape(energies, \n",
    "                            (K.shape(energies)[0], 1, K.shape(energies)[1]))\n",
    " \n",
    "        # Get the distance matrix and do some linear combination\n",
    "        dists_3 = getDistanceMatrix(\n",
    "                            K.permute_dimensions(x[:, 1:, :], (0, 2, 1)))\n",
    "        dists_0 = getDistanceMatrix(\n",
    "                            K.permute_dimensions(x[:, 0, None, :], (0, 2, 1)))\n",
    "        dists = dists_0 - dists_3\n",
    "        \n",
    "        dists = K.dot(dists, self.distanceCombination)\n",
    "        dists = K.permute_dimensions(dists, (0, 2, 1))\n",
    "\n",
    "        return K.concatenate([mass, pT, energies, dists], axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 7, input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoLaClassifier():\n",
    "    def __init__(self, nConstituents, nAdded, tag=0):\n",
    "        self.tag = tag\n",
    "        self.model = self._genNetwork(nConstituents, nAdded)\n",
    "        pass\n",
    "\n",
    "    def _genNetwork(self, nConstituents, nAdded):\n",
    "        input = Input((4, nConstituents))\n",
    "        layer = input\n",
    "\n",
    "        # Combination layer adds nAdded linear combinations of vectors\n",
    "        layer = CoLa(nAdded=nAdded, name='cola')(layer)\n",
    "        # LoLa replaces the 4 vectors by physically more meaningful vectors\n",
    "        layer = LoLa(name='lola')(layer) \n",
    "\n",
    "        # Connect to a fully connected network for classification\n",
    "        layer = Flatten()(layer)\n",
    "        layer = Dense(100, activation='relu')(layer)\n",
    "        layer = Dense(50, activation='relu')(layer)\n",
    "        layer = Dense(10, activation='relu')(layer)\n",
    "        layer = Dense(2, activation='softmax')(layer)\n",
    "        \n",
    "        model = keras.Model(input, layer)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filenames, nJets=slice(200000), nConstituents=10):\n",
    "    with h5py.File(filenames[0], 'r') as f:\n",
    "        bg_momenta = f['momenta'][nJets, :nConstituents, :]\n",
    "        bg_labels = np.zeros(len(bg_momenta))\n",
    "    \n",
    "    with h5py.File(filenames[1], 'r') as f:\n",
    "        sig_momenta = f['momenta'][nJets, :nConstituents, :]\n",
    "        sig_labels = np.ones(len(sig_momenta))\n",
    "\n",
    "    momenta = np.append(bg_momenta, sig_momenta, axis=0)\n",
    "\n",
    "    labels = keras.utils.to_categorical(\n",
    "            np.append(bg_labels, sig_labels), 2)\n",
    "    indices = np.random.permutation(len(labels))\n",
    "    print(momenta.shape, labels.shape)\n",
    "    return momenta[indices], labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJetMomenta(filenames, nJets=slice(200000), nConstituents=10):\n",
    "    \"\"\"Load jet momenta from given files\n",
    "    Input:\n",
    "     filenames: (2,) - list containing path to bg and sig jet momenta\n",
    "     nJets: slice - indices for loading data\n",
    "     nConstituents: int giving number of leading pT constituents per jet\n",
    "    Returns:\n",
    "     momenta: (nJets, 4, nConstituents) shuffled array of jet momenta\n",
    "     labels: (nJets, 2) one hot encoded labels for momenta\n",
    "    \"\"\"\n",
    "    print(\"Loading by given slice {}\".format(nJets))\n",
    "    # Load momenta from bg_file\n",
    "    with h5py.File(filenames[0], 'r') as f:\n",
    "        if f['momenta'].shape[-1] == 4:\n",
    "            bg_momenta = f['momenta'][nJets, :nConstituents, :]\n",
    "        elif f['momenta'].shape[-2] == 4:\n",
    "            bg_momenta = f['momenta'][nJets, :, :nConstituents]\n",
    "            bg_momenta = np.transpose(bg_momenta, (0, 2, 1))\n",
    "        else:\n",
    "            print(\"Momenta cannot be loaded\")\n",
    "            exit()\n",
    "        bg_labels = np.zeros(len(bg_momenta))\n",
    "        print(\"\\n{} bg jets loaded from {}\".format(\n",
    "            len(bg_labels), filenames[0]))\n",
    "\n",
    "    # Load momenta from sig_file\n",
    "    with h5py.File(filenames[1], 'r') as f:\n",
    "        if f['momenta'].shape[-1] == 4:\n",
    "            sig_momenta = f['momenta'][nJets, :nConstituents, :]\n",
    "        elif f['momenta'].shape[-2] == 4:\n",
    "            sig_momenta = f['momenta'][nJets, :, :nConstituents]\n",
    "            sig_momenta = np.transpose(sig_momenta, (0, 2, 1))\n",
    "        else:\n",
    "            print(\"Momenta cannot be loaded\")\n",
    "            exit()\n",
    "            \n",
    "        sig_labels = np.ones(len(sig_momenta))\n",
    "        print(\"{} sig jets loaded from {}\\n\\n\".format(\n",
    "            len(sig_labels), filenames[1]))\n",
    "\n",
    "\n",
    "    # Connect momenta, shuffle and return them with corresponding labels\n",
    "    momenta = np.append(bg_momenta, sig_momenta, axis=0)\n",
    "    labels = keras.utils.to_categorical(\n",
    "            np.append(bg_labels, sig_labels), 2)\n",
    "    indices = np.random.permutation(len(labels))\n",
    "    print(momenta.shape, labels.shape)\n",
    "    return momenta[indices], labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadJetMomentaBenchmark(filename, nConstituents=10, start=None, end=100000):\n",
    "    \"\"\"Load jet momenta from top tagging dataset as used in arXiv:1902.09914\n",
    "    Input:\n",
    "     filename: str, path to file\n",
    "     nConstituents: int, number of constituents loaded for each jet\n",
    "     start: int, index from which to start select events\n",
    "     end: int, index up to which select events\n",
    "    Returns:\n",
    "     momenta: (nJets, 4, nConstituents), array with 4 momenta of jet constituents\n",
    "     labels: (nJets, 2), one-hot encoded labels for jets\n",
    "    \"\"\"\n",
    "\n",
    "    with pandas.HDFStore(filename, 'r') as store:\n",
    "        print(\"Loading indices from {} to {}\".format(start, end))\n",
    "        events = store.select(\"table\", start=start, stop=end)\n",
    "        momenta = events.values[:, :nConstituents*4]\n",
    "        momenta = np.reshape(momenta, (len(momenta), nConstituents, 4))\n",
    "        momenta = np.transpose(momenta, [0, 2, 1])\n",
    "        labels = events.values[:, -1]\n",
    "        print('\\nMean label\\n{}\\n'.format(np.mean(labels)))\n",
    "        labels = keras.utils.to_categorical(labels, 2)\n",
    "\n",
    "    indices = np.random.permutation(len(labels))\n",
    "    return momenta[indices], labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices from None to 100000\n",
      "\n",
      "Mean label\n",
      "0.5004\n",
      "\n",
      "Loading indices from None to 100000\n",
      "\n",
      "Mean label\n",
      "0.5019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_momenta,train_labels=loadJetMomentaBenchmark(\"train.h5\")\n",
    "val_momenta,val_labels=loadJetMomentaBenchmark(\"val.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-a4c83f3313ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_dataset.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "train_dataset= h5py.File(\"train_dataset.h5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.create_dataset('momenta', data=train_momenta)\n",
    "train_dataset.create_dataset('labels', data=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset= h5py.File(\"val_dataset.h5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.create_dataset('momenta', data=val_momenta)\n",
    "val_dataset.create_dataset('labels', data=val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 4, 40) (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "vectors, labels = loadData(\n",
    "                filenames = [\"train_dataset.h5\", \"train_dataset.h5\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = LoLaClassifier(nConstituents=40, nAdded=10).model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 4, 40)             0         \n",
      "_________________________________________________________________\n",
      "cola (CoLa)                  (None, 4, 50)             400       \n",
      "_________________________________________________________________\n",
      "lola (LoLa)                  (None, 7, 50)             2704      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               35100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 43,786\n",
      "Trainable params: 43,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.8160 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.6931 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4966 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 30/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 32/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4975 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 33/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 34/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 37/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 39/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 40/100\n",
      " - 9s - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 41/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 42/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 43/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 45/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5015 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 46/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 47/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 48/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 49/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 51/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 52/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 57/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 63/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 65/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 66/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 67/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 68/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 69/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5012 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 70/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 71/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 72/100\n",
      " - 8s - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 73/100\n",
      " - 7s - loss: 0.6931 - acc: 0.5025 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 74/100\n",
      " - 8s - loss: 0.6932 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 76/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 78/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 80/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4970 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 81/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 82/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 83/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 84/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 85/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 86/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4984 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 87/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.4998\n",
      "Epoch 88/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 89/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 90/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 91/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 92/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 93/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 94/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 95/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6931 - val_acc: 0.5002\n",
      "Epoch 96/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 98/100\n",
      " - 7s - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4998\n",
      "Epoch 99/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.5002\n",
      "Epoch 100/100\n",
      " - 7s - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.4998\n"
     ]
    }
   ],
   "source": [
    "model111 = model.fit(vectors, labels,\n",
    "        verbose=2,\n",
    "        batch_size=512,\n",
    "        validation_split=0.1,\n",
    "        epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b118e16908>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(model111.history['loss'])\n",
    "plt.plot(model111.history['val_loss'])\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training set','validation set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
